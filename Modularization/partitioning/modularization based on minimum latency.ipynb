{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e671f5d-4d78-4c19-ba44-824d61b9824e",
   "metadata": {},
   "source": [
    "# modularization based on minimum latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bedee9f-cc1e-40cc-b486-7b3a574e892f",
   "metadata": {},
   "source": [
    "## Overall flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d4740-9b56-4fee-b103-4489e88b8b00",
   "metadata": {},
   "source": [
    "![general_flow](general_flow.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29ce9e-8cd0-46b5-ae3f-9045d4c43df1",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e11f24-a777-414e-ae80-fc5b7ffb944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import json\n",
    "\n",
    "from prepare_model import prepareModel\n",
    "from com_latency_estimate import com_latency\n",
    "from generate_report import generateReport\n",
    "from cut import generate_block\n",
    "from fussion_parallelize import fussionParallelize\n",
    "\n",
    "build_dir = \"../../../../notebooks/GitHub/M_Project/Patitioning/tmp\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857fd7c-a505-4dea-b421-02225f5db631",
   "metadata": {},
   "source": [
    "## Model and Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea9ab9-f09d-44cf-bdf1-c641cd76288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cnv_e50_1bit_trained\"\n",
    "model_dir = \"../../../../notebooks/GitHub/M_Project/Model/tmp\"\n",
    "model_finn_path = prepareModel(model_name, build_dir, model_dir)\n",
    "model_folded_path = fussionParallelize(build_dir, os.path.basename(model_finn_path)) # include optimization and folding configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805fa07b-e114-4788-8fac-7ea2169d546c",
   "metadata": {},
   "source": [
    "## Prtitioning Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49042b7-e8f0-4a31-95c1-845af82a4d70",
   "metadata": {},
   "source": [
    "### Constarint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1bde5-e22f-4871-8980-acc5be41d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('device_profiles.ini')\n",
    "\n",
    "maxNumberOfDevices = int(config[\"GLOBAL\"][\"maxNumberOfDevices\"])\n",
    "frequency = int(config[\"GLOBAL\"][\"frequency\"])\n",
    "\n",
    "devices = [];\n",
    "for d in range(maxNumberOfDevices):\n",
    "    device = {}\n",
    "    device[\"maxLUT\"] = int(config[f\"Device_{d}\"][\"maxLUT\"])\n",
    "    device[\"maxBRAM\"] = int(config[f\"Device_{d}\"][\"maxBRAM\"])\n",
    "    #device[\"maxCommunication\"] = int(config[f\"Device_{d}\"][\"maxCommunication\"])\n",
    "    devices.append(device)\n",
    "\n",
    "lib = {\n",
    "\"INT8\": 8,\n",
    "\"BINARY\": 1,\n",
    "\"UINT32\": 32}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0075b146-1992-4f81-bad5-d138ec65c10c",
   "metadata": {},
   "source": [
    "### Design Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b4466-e6cf-4fbf-9f65-17c78b274f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_communication_cost(output_shapes, frequency=1330000000000): # maximum KV@^) board frequency\n",
    "    cost = com_latency(output_shapes, frequency, batchsize=16)\n",
    "    cost *= 10**9 # change to nano\n",
    "    return cost\n",
    "\n",
    "def sub_block_resource_precompute(number_of_nodes, node_lut, node_bram, node_latency):\n",
    "    execution_latency = [[0] * number_of_nodes for _ in range(number_of_nodes)]\n",
    "    lut_usage = [[0] * number_of_nodes for _ in range(number_of_nodes)]\n",
    "    bram_usage = [[0] * number_of_nodes for _ in range(number_of_nodes)] \n",
    "\n",
    "    for start in range(number_of_nodes):\n",
    "        lut_sum, bram_sum, exec_sum = 0, 0, 0\n",
    "        for end in range(start, number_of_nodes):            \n",
    "            lut_sum += node_lut[end]\n",
    "            bram_sum += node_bram[end]\n",
    "            exec_sum += node_latency[end]\n",
    "\n",
    "            execution_latency[start][end] = exec_sum\n",
    "            lut_usage[start][end] = lut_sum\n",
    "            bram_usage[start][end] = bram_sum\n",
    "    return execution_latency, lut_usage, bram_usage\n",
    "\n",
    "def get_nodes_information(number_of_nodes, model_folded_path, target_clk_ns):\n",
    "    node_latency = []  \n",
    "    node_lut = []\n",
    "    node_bram = []\n",
    "    output_shapes = []\n",
    "    output_sizes = []\n",
    "    output_dtypes = []\n",
    "\n",
    "    for n in range(number_of_nodes):\n",
    "        start_node = n\n",
    "        end_node = start_node + 1\n",
    "        path_submodel, output_shape, output_dtype, input_shape, input_dtype = generate_block(model_folded_path, start_node, end_node)\n",
    "        estimate_layer_resources, estimate_network_performance = generateReport(ModelWrapper(path_submodel), target_clk_ns)\n",
    "        output_element = 1\n",
    "        for size in output_shape:\n",
    "            output_element = output_element*size\n",
    "        node_latency.append(estimate_network_performance[\"estimated_latency_ns\"])\n",
    "        node_lut.append(estimate_layer_resources[\"total\"][\"LUT\"])\n",
    "        node_bram.append(estimate_layer_resources[\"total\"][\"BRAM_18K\"])\n",
    "        output_shapes.append(output_shape)\n",
    "        output_sizes.append(output_shape)#output_element)\n",
    "        output_dtypes.append(str(output_dtype))\n",
    "    return node_latency, node_lut, node_bram, output_shapes, output_sizes, output_dtypes\n",
    "    \n",
    "def generate_partitioning_configuration(num_devices, lut_usage, bram_usage, max_lut, max_bram, \n",
    "                    output_shapes, execution_latency, communication_latency_fn):\n",
    "    num_nodes = len(lut_usage)\n",
    "\n",
    "    # Helper function to compute block latency\n",
    "    def compute_latency(start, end, device_idx):\n",
    "        exec_latency = sum(execution_latency[start:end])\n",
    "        if start > 0:  # Communication cost from previous block\n",
    "            comm_latency = communication_latency_fn(output_shapes[start-1])\n",
    "        else:\n",
    "            comm_latency = 0\n",
    "        return  comm_latency + exec_latency\n",
    "        \n",
    "    # Helper function to check resource constraints for a block\n",
    "    def is_valid_block(start, end, device_idx):\n",
    "        #print(f\"device: {str(device_idx):<2}, start: {str(start):<3}, end: {str(end):<3}, total lut: {str(lut_usage[start:end])}\")\n",
    "        total_lut = sum(lut_usage[start:end])\n",
    "        total_bram = sum(bram_usage[start:end])\n",
    "        return total_lut <= max_lut[device_idx] and total_bram <= max_bram[device_idx]\n",
    "    \n",
    "\n",
    "   \n",
    "    # Initialize results\n",
    "    best_latency = float('inf')\n",
    "    best_split = None\n",
    "    best_devices = 0\n",
    "\n",
    "    # Explore all possible splits for 1 to num_devices\n",
    "    for d in range(3, num_devices):\n",
    "        # DP table to store the minimum latency for splitting the first i nodes into j devices\n",
    "        dp = [[float('inf')] * (d + 1) for _ in range(num_nodes + 1)]\n",
    "        split = [[None] * (d + 1) for _ in range(num_nodes + 1)]\n",
    "        dp[0][0] = 0  # Base case: 0 latency with 0 nodes and 0 devices\n",
    "\n",
    "        for i in range(1, num_nodes + 1):  # For each node\n",
    "            for j in range(1, d + 1):  # For each device\n",
    "                for k in range(i):  # Split point\n",
    "                    if is_valid_block(k, i, j - 1):  # Check resource constraints\n",
    "\n",
    "                        if i == 0 :\n",
    "                            latency = dp[k][j - 1] + compute_latency(k, i, j - 1)\n",
    "                        else:\n",
    "                            latency = dp[k-1][j - 1] + compute_latency(k, i, j - 1)  \n",
    "\n",
    "                        ### debugging start\n",
    "                        #if d == 3:\n",
    "                        #    if k == 15:\n",
    "                        #        print(f\"dp[k][j - 1]: {str(dp[k][j - 1])}\")\n",
    "                        #        print(f\"latency: {latency}\")\n",
    "                        ### debugging end    \n",
    "                        if latency < dp[i][j]:\n",
    "                            dp[i][j] = latency\n",
    "                            split[i][j] = k\n",
    "\n",
    "        # Check if this configuration gives better latency\n",
    "        if dp[num_nodes][d] < best_latency:\n",
    "            best_latency = dp[num_nodes][d]\n",
    "            best_devices = d\n",
    "\n",
    "            # Recover the split configuration\n",
    "            best_split = []\n",
    "            current_node = num_nodes\n",
    "            for j in range(d, 0, -1):\n",
    "                prev_node = split[current_node-1][j] \n",
    "                best_split.append(list(range(prev_node, current_node)))\n",
    "                current_node = prev_node\n",
    "            best_split.reverse()  # Reverse to get the correct order\n",
    "        #####\n",
    "        #df = pd.DataFrame(dp)\n",
    "        #print(df)\n",
    "\n",
    "    return best_devices, best_split, best_latency#, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63e9d4-d969-4ae6-954f-f4411baf7acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ModelWrapper(model_folded_path)\n",
    "number_of_nodes = len(model.graph.node)\n",
    "num_devices = len(devices)-1\n",
    "max_lut=[]\n",
    "max_bram=[]\n",
    "for d in devices:\n",
    "    max_lut.append(d[\"maxLUT\"])\n",
    "    max_bram.append(d[\"maxBRAM\"])\n",
    "\n",
    "node_latency, node_lut, node_bram, output_shapes, output_sizes, output_dtypes = get_nodes_information(number_of_nodes, \n",
    "                                                                                                      model_folded_path, \n",
    "                                                                                                      target_clk_ns=10)\n",
    "best_devices, best_split,best_latency = generate_partitioning_configuration(num_devices=maxNumberOfDevices, \n",
    "                                           lut_usage=node_lut, \n",
    "                                           bram_usage=node_bram, \n",
    "                                           max_lut=max_lut, \n",
    "                                           max_bram=max_bram, \n",
    "                                           output_shapes=output_shapes, \n",
    "                                           execution_latency=node_latency, \n",
    "                                           communication_latency_fn=estimate_communication_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53bb63-28c0-4f84-933c-9fb550eb128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, b in enumerate(best_split):\n",
    "    print(f\"module: {i:<3} start: {b[0]:<4} end: {b[-1]:<4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405f648-d462-4e7d-81a0-844fead6918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(\"output_shapes\")\n",
    "for index, output_shape in enumerate(output_shapes):\n",
    "    total_elements = math.prod(output_shape)\n",
    "    print(f\"{index:<5} {str(output_shape):<20} {total_elements:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097822e-a0d9-46b3-b524-9f123be26752",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_elements = 0\n",
    "print(\"node_bram\")\n",
    "for index, nl in enumerate(node_bram):\n",
    "    total_elements += nl\n",
    "    print(f\"{index:<5} {str(nl):<20} {total_elements:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea94f8-da3b-4324-80cf-83ea89e935a1",
   "metadata": {},
   "source": [
    "## Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c24ec-8198-4935-a581-49608b287bca",
   "metadata": {},
   "source": [
    "### generate sub model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a681c4c-e5fd-43b3-9fc2-810519e7822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_assignment = []\n",
    "for blck in best_split:\n",
    "    optimal_assignment.append((blck[0],blck[-1]))\n",
    "optimal_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70f7df-34c0-425d-ada1-73a16584ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from qonnx.transformation.general import GiveUniqueNodeNames\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "sub_modules_path = []\n",
    "\n",
    "for block_cfg in optimal_assignment:\n",
    "    path_submodel, output_shape, output_dtype, input_shape, input_dtype = generate_block(model_folded_path, block_cfg[0], block_cfg[1]+1)\n",
    "    # change the ouput tensor\n",
    "    model = ModelWrapper(path_submodel)\n",
    "    model = model.transform(RemoveUnusedTensors())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model.set_tensor_shape(\"global_out\", output_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    # change the input tensor\n",
    "    model.set_tensor_shape(ModelWrapper(path_submodel).graph.node[0].input[0], input_shape, dtype=onnx.TensorProto.FLOAT)\n",
    "    model = model.transform(RemoveUnusedTensors())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    \n",
    "    model.save(path_submodel)\n",
    "    sub_modules_path.append(path_submodel)\n",
    "sub_modules_path;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b015ef78-6147-4db4-ae83-1d0786e34295",
   "metadata": {},
   "source": [
    "## Synthesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f9f3ac-dd28-42cc-838e-6eaf6b28c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "from qonnx.transformation.general import GiveUniqueNodeNames\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "from finn.util.basic import make_build_dir\n",
    "from shutil import copy\n",
    "from distutils.dir_util import copy_tree\n",
    "import uuid\n",
    "\n",
    "test_pynq_board = \"KV260_SOM\"\n",
    "target_clk_ns = 10\n",
    "deployment_directories = []\n",
    "final_modules_directories = []\n",
    "\n",
    "for block in sub_modules_path:\n",
    "    module = ModelWrapper(block)\n",
    "    module = module.transform(RemoveUnusedTensors())\n",
    "    module = module.transform(GiveUniqueNodeNames())\n",
    "    module = module.transform(ZynqBuild(platform = test_pynq_board, period_ns = target_clk_ns))\n",
    "    module = module.transform(MakePYNQDriver(\"zynq-iodma\"))\n",
    "\n",
    "    deployment_dir = make_build_dir(prefix=\"pynq_deployment_\")\n",
    "    module.set_metadata_prop(\"pynq_deployment_dir\", deployment_dir)\n",
    "    deployment_directories.append(deployment_dir)\n",
    "\n",
    "    bitfile = module.get_metadata_prop(\"bitfile\")\n",
    "    hwh_file = module.get_metadata_prop(\"hw_handoff\")\n",
    "    deploy_files = [bitfile, hwh_file]\n",
    "    for dfile in deploy_files:\n",
    "        if dfile is not None:\n",
    "            copy(dfile, deployment_dir)\n",
    "    pynq_driver_dir = module.get_metadata_prop(\"pynq_driver_dir\")\n",
    "    copy_tree(pynq_driver_dir, deployment_dir)\n",
    "\n",
    "    final_modules_directory = build_dir + f\"/{str(uuid.uuid4())}.onnx\"\n",
    "    module.save(final_modules_directory)\n",
    "    final_modules_directories.append(final_modules_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1ce17-26f7-40c2-abc8-e9b3feda65f9",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1a36d-d2ea-4e31-a3fe-b3c744b953cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report = [ str(deployment_directories), str(final_modules_directories)]\n",
    "with open('report.txt', 'w') as file:\n",
    "    json.dump(final_report, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92462e1f-0cc1-4805-811f-0e6ac6d476c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "final_report = [str(sub_modules_report), str(deployment_directories), str(final_modules_directories)]\n",
    "with open('example_report_summary.txt', 'w') as file:\n",
    "    json.dump(final_report, file, indent=4)\n",
    "print(\"example_report_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92492a-28dd-45a4-bd0b-f4ae2899e87e",
   "metadata": {},
   "source": [
    "#### option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db377c30-b980-4c45-baf3-a8ef6ddfe59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_design_space_with_combinations(dp, split_point, number_of_nodes, num_devices):\n",
    "    # Store each configuration of latency and device count\n",
    "    device_counts = list(range(1, num_devices + 1))\n",
    "    all_configurations = []\n",
    "    \n",
    "    # Collect all possible layer combinations and corresponding latencies\n",
    "    for j in device_counts:\n",
    "        # Collect all latencies and assignments for the j-device configuration\n",
    "        config_latencies = []\n",
    "        for i in range(1, number_of_nodes + 1):\n",
    "            if dp[i][j] != float('inf'):  # Only plot valid configurations\n",
    "                # Traverse split points to get all combinations\n",
    "                assignment = []\n",
    "                layer = i\n",
    "                devices_left = j\n",
    "                while devices_left > 0 and layer > 0:\n",
    "                    start_layer = split_point[layer][devices_left]\n",
    "                    assignment.append((start_layer, layer - 1))\n",
    "                    layer = start_layer\n",
    "                    devices_left -= 1\n",
    "                assignment = assignment[::-1]  # Reverse to start from layer 0\n",
    "                config_latencies.append((dp[i][j], assignment))\n",
    "        \n",
    "        # Store each unique latency and assignment per device count j\n",
    "        all_configurations.append((j, config_latencies))\n",
    "\n",
    "    # Plot each device count's configurations with different markers\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for j, configs in all_configurations:\n",
    "        for latency, assignment in configs:\n",
    "            # Scatter each latency point for the device count `j`\n",
    "            plt.scatter(j, latency, label=f'Devices: {j}, Layers: {assignment}')\n",
    "    \n",
    "    # Find and annotate the optimal configuration\n",
    "    optimal_latency = min(dp[number_of_nodes][j] for j in device_counts)\n",
    "    optimal_devices = min(device_counts, key=lambda j: dp[number_of_nodes][j])\n",
    "    \n",
    "    plt.xlabel('Number of Devices')\n",
    "    plt.ylabel('Total Latency')\n",
    "    plt.title('Design Space: Latency for Layer Assignments Across Devices')\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.4, 1), fontsize='small', title=\"Assignments\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Annotate optimal point\n",
    "    plt.annotate(f'Optimal: {optimal_devices} devices\\nLatency: {optimal_latency}',\n",
    "                 xy=(optimal_devices, optimal_latency),\n",
    "                 xytext=(optimal_devices + 0.3, optimal_latency + 0.05 * optimal_latency),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1cf49-3214-47b7-be00-8f9c85ddd8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_design_space_with_combinations(dp,split_point, 19, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3c7a6-1053-495a-8565-7228cb36863f",
   "metadata": {},
   "source": [
    "#### option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de6be1-0caf-41d1-bb60-46e718b4c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feasible_design_space(dp, split_point, number_of_nodes, num_devices, max_lut, max_bram, lut_usage, bram_usage):\n",
    "    # Store configurations that meet all criteria\n",
    "    device_counts = list(range(1, num_devices + 1))\n",
    "    feasible_configurations = []\n",
    "\n",
    "    # Collect feasible layer assignments and corresponding latencies\n",
    "    for j in device_counts:\n",
    "        # Only consider configurations that process all nodes\n",
    "        if dp[number_of_nodes][j] < float('inf'):  # Feasible configuration check\n",
    "            # Reconstruct layer assignment for this device configuration\n",
    "            assignment = []\n",
    "            layer = number_of_nodes\n",
    "            devices_left = j\n",
    "            valid_assignment = True\n",
    "            \n",
    "            while devices_left > 0 and layer > 0:\n",
    "                start_layer = split_point[layer][devices_left]\n",
    "                # Check if the configuration meets resource constraints\n",
    "                if start_layer != -1 and lut_usage[start_layer][layer - 1] <= max_lut and bram_usage[start_layer][layer - 1] <= max_bram:\n",
    "                    assignment.append((start_layer, layer - 1))\n",
    "                    layer = start_layer\n",
    "                    devices_left -= 1\n",
    "                else:\n",
    "                    valid_assignment = False\n",
    "                    break  # Invalid configuration, skip\n",
    "                \n",
    "            # Only add valid, feasible assignments that cover all nodes\n",
    "            if valid_assignment and layer == 0:\n",
    "                assignment = assignment[::-1]  # Reverse to show assignment from layer 0\n",
    "                feasible_configurations.append((j, dp[number_of_nodes][j], assignment))\n",
    "\n",
    "    # Plot each feasible configuration with device counts on the x-axis and latency on the y-axis\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for devices, latency, assignment in feasible_configurations:\n",
    "        plt.scatter(devices, latency, label=f'Devices: {devices}, Layers: {assignment}')\n",
    "\n",
    "    # Identify the optimal feasible configuration\n",
    "    optimal_config = min(feasible_configurations, key=lambda x: x[1])\n",
    "    optimal_devices, optimal_latency, optimal_assignment = optimal_config\n",
    "\n",
    "    # Plot annotations and details\n",
    "    plt.xlabel('Number of Devices')\n",
    "    plt.ylabel('Total Latency')\n",
    "    plt.title('Feasible Design Space: Latency vs Number of Devices with Valid Layer Assignments')\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1), fontsize='small', title=\"Assignments\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Annotate optimal point\n",
    "    plt.annotate(f'Optimal: {optimal_devices} devices\\nLatency: {optimal_latency}',\n",
    "                 xy=(optimal_devices, optimal_latency),\n",
    "                 xytext=(optimal_devices + 0.3, optimal_latency + 0.05 * optimal_latency),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ba7b7-3081-4644-a191-8d7e73ae5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feasible_design_space(dp, split_point, 19, 3, 24000, 24000, lut_usage, bram_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db291023-3579-4716-9c23-5d6e700fd789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf69afd4-2b90-442b-8300-78b9d695d536",
   "metadata": {},
   "source": [
    "#### option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c3f93-5956-4fd6-ad78-658623831abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import MagicMock\n",
    "\n",
    "class TestOptimalLatency(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        # Mock input data for testing\n",
    "        self.number_of_nodes = 5\n",
    "        self.num_devices = 3\n",
    "        self.target_clk_ns = 10\n",
    "\n",
    "        # Mock device constraints\n",
    "        self.devices = [\n",
    "            {\"maxLUT\": 1000, \"maxBRAM\": 500},\n",
    "            {\"maxLUT\": 2000, \"maxBRAM\": 1000},\n",
    "            {\"maxLUT\": 3000, \"maxBRAM\": 1500},\n",
    "        ]\n",
    "\n",
    "        # Mock node information\n",
    "        self.node_latency = [100, 200, 150, 300, 250]\n",
    "        self.node_lut = [500, 400, 300, 700, 600]\n",
    "        self.node_bram = [200, 150, 100, 250, 200]\n",
    "        self.output_sizes = [500, 400, 300, 700, 600]\n",
    "\n",
    "        # Mock model_folded_path, just for placeholder\n",
    "        self.model_folded_path = \"mock_model_path\"\n",
    "        self.com_frequency = 1e8  # Example communication frequency\n",
    "\n",
    "    def test_estimate_communication_cost(self):\n",
    "        output_shapes = [10, 20, 30]\n",
    "        output_dtypes = \"float32\"\n",
    "        frequency = 1e8  # Example frequency\n",
    "\n",
    "        # Assume 32 bits per float and 6000 elements\n",
    "        expected_cost = (1 / frequency) * 32 * 6000 * 1e9\n",
    "        cost, elements = estimate_communication_cost(output_shapes, output_dtypes, frequency)\n",
    "        \n",
    "        self.assertAlmostEqual(cost, expected_cost)\n",
    "        self.assertEqual(elements, 6000)\n",
    "\n",
    "    def test_get_nodes_information(self):\n",
    "        # Mocking the required external calls within get_nodes_information\n",
    "        ModelWrapper = MagicMock()\n",
    "        ModelWrapper.return_value.graph.node = [None] * self.number_of_nodes\n",
    "\n",
    "        generate_block = MagicMock()\n",
    "        generate_block.return_value = (\"mock_path\", [10, 20], \"float32\", [10], \"float32\")\n",
    "\n",
    "        generateReport = MagicMock()\n",
    "        generateReport.return_value = (\n",
    "            {\"total\": {\"LUT\": 300, \"BRAM_18K\": 100}},\n",
    "            {\"estimated_latency_ns\": 150}\n",
    "        )\n",
    "\n",
    "        # Run the function\n",
    "        latencies, luts, brams, shapes, sizes, dtypes = get_nodes_information(\n",
    "            self.number_of_nodes, self.model_folded_path, self.target_clk_ns\n",
    "        )\n",
    "\n",
    "        # Assert values are returned correctly\n",
    "        self.assertEqual(len(latencies), self.number_of_nodes)\n",
    "        self.assertEqual(len(luts), self.number_of_nodes)\n",
    "        self.assertEqual(len(brams), self.number_of_nodes)\n",
    "\n",
    "    def test_prepare_state_space(self):\n",
    "        dp, split_point = prepare_state_space(self.num_devices, self.number_of_nodes)\n",
    "        \n",
    "        # Check dp and split_point structure\n",
    "        self.assertEqual(len(dp), self.number_of_nodes + 1)\n",
    "        self.assertEqual(len(dp[0]), self.num_devices + 1)\n",
    "        self.assertEqual(dp[0][1], 0)  # Initial state set to zero\n",
    "\n",
    "    def test_dynamic_programming(self):\n",
    "        dp, split_point = prepare_state_space(self.num_devices, self.number_of_nodes)\n",
    "        execution_latency, lut_usage, bram_usage = sub_block_resource_precompute(\n",
    "            self.number_of_nodes, self.node_lut, self.node_bram, self.node_latency\n",
    "        )\n",
    "\n",
    "        dynamic_programming(\n",
    "            self.num_devices,\n",
    "            self.number_of_nodes,\n",
    "            lut_usage,\n",
    "            bram_usage,\n",
    "            self.devices,\n",
    "            self.output_sizes,\n",
    "            dp,\n",
    "            execution_latency,\n",
    "            split_point\n",
    "        )\n",
    "\n",
    "        # Verify that the dp table has been updated with finite values\n",
    "        self.assertNotEqual(dp[self.number_of_nodes][1], float('inf'))\n",
    "        self.assertNotEqual(dp[self.number_of_nodes][2], float('inf'))\n",
    "\n",
    "    def test_reconstruct_layers(self):\n",
    "        dp, split_point = prepare_state_space(self.num_devices, self.number_of_nodes)\n",
    "        execution_latency, lut_usage, bram_usage = sub_block_resource_precompute(\n",
    "            self.number_of_nodes, self.node_lut, self.node_bram, self.node_latency\n",
    "        )\n",
    "\n",
    "        # Run dynamic programming to fill dp and split_point tables\n",
    "        dynamic_programming(\n",
    "            self.num_devices,\n",
    "            self.number_of_nodes,\n",
    "            lut_usage,\n",
    "            bram_usage,\n",
    "            self.devices,\n",
    "            self.output_sizes,\n",
    "            dp,\n",
    "            execution_latency,\n",
    "            split_point\n",
    "        )\n",
    "\n",
    "        # Assume optimal_devices is set after finding minimum latency\n",
    "        optimal_devices = 2\n",
    "        assignments, devices_used = reconstruct_layers(self.number_of_nodes, optimal_devices, split_point)\n",
    "\n",
    "        # Check that assignments cover all layers\n",
    "        covered_layers = set()\n",
    "        for start, end in assignments:\n",
    "            for layer in range(start, end + 1):\n",
    "                covered_layers.add(layer)\n",
    "\n",
    "        self.assertEqual(len(covered_layers), self.number_of_nodes)\n",
    "\n",
    "    def test_optimal_configuration(self):\n",
    "        min_latency, optimal_devices, optimal_assignment, dp, split_point, lut_usage, bram_usage = optimal_configuration(\n",
    "            self.model_folded_path,\n",
    "            self.devices,\n",
    "            self.com_frequency,\n",
    "            self.target_clk_ns\n",
    "        )\n",
    "\n",
    "        # Verify that all nodes are covered in the assignment\n",
    "        covered_layers = set()\n",
    "        for start, end in optimal_assignment:\n",
    "            for layer in range(start, end + 1):\n",
    "                covered_layers.add(layer)\n",
    "\n",
    "        self.assertEqual(len(covered_layers), self.number_of_nodes)\n",
    "        self.assertLessEqual(optimal_devices, self.num_devices)\n",
    "        self.assertTrue(min_latency >= 0)  # Latency should be non-negative\n",
    "\n",
    "# Run all tests\n",
    "#if __name__ == \"__main__\":\n",
    "#    unittest.main()\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039e898-8f5e-472b-bd31-872f4c0d5962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2b1a1-9ba8-43f7-a3ae-f39db4bdf102",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_latency = [30720, 81960, 324000, 142920, 282240, 9800, 26760, 207360, 37440, 288000, 1250, 3840, 207360, 1440,184320 ,327680, 327680, 5120, 20]  \n",
    "node_lut = [16.0, 396.0, 2746.0, 428.0, 7410.0, 0, 428.0, 3855.0, 428.0, 3872.0, 0, 428.0, 1193.0, 428.0, 524.0,  336.0,363.0, 335.0, 0 ]  \n",
    "node_bram = [0.0, 0.0, 2.0, 0.0, 29.0, 0.0, 0.0, 15.0, 0.0, 15.0, 0.0, 0.0, 24.0, 0.0, 36.0,  8.0, 16.0, 1.0, 0 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead30eb3-f30b-4314-8559-aff7ca3019a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_latency(number_of_nodes, frequency, max_lut, max_bram, num_devices):\n",
    "    # Precompute execution times and resource usage for each sub-block of layers\n",
    "    execution_latency = [[0] * number_of_nodes for _ in range(number_of_nodes)]\n",
    "    lut_usage = [[0] * number_of_nodes for _ in range(number_of_nodes)]\n",
    "    bram_usage = [[0] * number_of_nodes for _ in range(number_of_nodes)] \n",
    "\n",
    "    for start in range(number_of_nodes):\n",
    "        lut_sum, bram_sum, exec_sum = 0, 0, 0\n",
    "        for end in range(start, number_of_nodes):            \n",
    "            lut_sum += node_lut[end]\n",
    "            bram_sum += node_bram[end]\n",
    "            exec_sum += node_latency[end]\n",
    "\n",
    "            execution_latency[start][end] = exec_sum\n",
    "            lut_usage[start][end] = lut_sum\n",
    "            bram_usage[start][end] = bram_sum\n",
    "\n",
    "    # DP table to store the minimum latency up to each layer with a given number of devices\n",
    "    dp = [[float('inf')] * (num_devices + 1) for _ in range(number_of_nodes + 1)]\n",
    "    split_point = [[-1] * (num_devices + 1) for _ in range(number_of_nodes + 1)]\n",
    "    \n",
    "\n",
    "    # Initialization for 1 device (all layers on one device)\n",
    "    dp[0][1] = 0\n",
    "\n",
    "    # Dynamic programming to find minimum latency configuration\n",
    "    for j in range(1, num_devices + 1):  # Device count\n",
    "        for i in range(1, number_of_nodes + 1):  # End layer for this device\n",
    "            for k in range(i):  # Split point\n",
    "                # Resource constraints check\n",
    "                if lut_usage[k][i - 1] <= max_lut and bram_usage[k][i - 1] <= max_bram:\n",
    "                    # Calculate latency for the current split configuration\n",
    "                    comm_latency = node_output_size[k - 1] * 0.01 if k > 0 else 0\n",
    "                    current_latency = dp[k][j - 1] + execution_latency[k][i - 1] + comm_latency\n",
    "\n",
    "                    # Update dp table if current latency is lower\n",
    "                    if current_latency < dp[i][j]:\n",
    "                        dp[i][j] = current_latency\n",
    "                        split_point[i][j] = k\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Find the minimum latency for the full model on the available devices\n",
    "    min_latency = min(dp[number_of_nodes][j] for j in range(1, num_devices + 1))\n",
    "    optimal_devices = min(range(0, num_devices + 1), key=lambda j: dp[number_of_nodes][j])\n",
    "\n",
    "    # Reconstruct the optimal device assignment from split_point table\n",
    "    def reconstruct_layers():\n",
    "        assignments = []\n",
    "        i, j = number_of_nodes, optimal_devices\n",
    "        while j > 1:\n",
    "            start_layer = split_point[i][j] #+ 1\n",
    "            assignments.append((start_layer, i - 1))\n",
    "            i, j = start_layer, j - 1\n",
    "        return assignments[::-1]\n",
    "\n",
    "    # Output results\n",
    "    optimal_assignment = reconstruct_layers()\n",
    "    optimal_devices -= 1\n",
    "    return {\n",
    "        \"min_latency\": min_latency,\n",
    "        \"optimal_devices\": optimal_devices,\n",
    "        \"assignments\": optimal_assignment\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ea4df-66c7-49c0-aa1c-8b9108bde66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_latency(model_folded_path, devices, com_frequency, target_clk_ns=10):\n",
    "    model = ModelWrapper(model_folded_path)\n",
    "    number_of_nodes = len(model.graph.node)\n",
    "    num_devices = len(devices)\n",
    "#################################################### gathering information of each node. report from finn\n",
    "    node_latency = []  \n",
    "    node_lut = []\n",
    "    node_bram = []\n",
    "    output_shapes = []\n",
    "    output_sizes = []\n",
    "    output_dtypes = []\n",
    "\n",
    "    for n in range(number_of_nodes):\n",
    "        #TODO: generate submodules\n",
    "        start_node = n\n",
    "        end_node = start_node + 1\n",
    "        path_submodel, output_shape, output_dtype = get_one_layer(model_folded_path, start_node, end_node)\n",
    "        estimate_layer_resources, estimate_network_performance = generateReport(ModelWrapper(path_submodel), target_clk_ns)\n",
    "        output_element = 1\n",
    "        for size in output_shape:\n",
    "            output_element = output_element*size\n",
    "        node_latency.append(estimate_network_performance[\"estimated_latency_ns\"])\n",
    "        node_lut.append(estimate_layer_resources[\"total\"][\"LUT\"])\n",
    "        node_bram.append(estimate_layer_resources[\"total\"][\"BRAM_18K\"])\n",
    "        output_shapes.append(output_shape)\n",
    "        output_sizes.append(output_element)\n",
    "        output_dtypes.append(str(output_dtype))\n",
    "    print(node_lut)\n",
    "    \n",
    "#######################################################\n",
    "\n",
    "    # Precompute execution times and resource usage for each sub-block of layers\n",
    "    execution_latency = [[0] * number_of_nodes for _ in range(number_of_nodes)]\n",
    "    lut_usage = [[0] * number_of_nodes for _ in range(number_of_nodes)]\n",
    "    bram_usage = [[0] * number_of_nodes for _ in range(number_of_nodes)] \n",
    "\n",
    "    for start in range(number_of_nodes):\n",
    "        lut_sum, bram_sum, exec_sum = 0, 0, 0\n",
    "        for end in range(start, number_of_nodes):            \n",
    "            lut_sum += node_lut[end]\n",
    "            bram_sum += node_bram[end]\n",
    "            exec_sum += node_latency[end]\n",
    "\n",
    "            execution_latency[start][end] = exec_sum\n",
    "            lut_usage[start][end] = lut_sum\n",
    "            bram_usage[start][end] = bram_sum\n",
    "\n",
    "    # DP table to store the minimum latency up to each layer with a given number of devices\n",
    "    dp = [[float('inf')] * (num_devices + 1) for _ in range(number_of_nodes + 1)]\n",
    "    split_point = [[-1] * (num_devices + 1) for _ in range(number_of_nodes + 1)]\n",
    "    \n",
    "    # Initialization for 1 device (all layers on one device)\n",
    "    dp[0][1] = 0\n",
    "\n",
    "    # Dynamic programming to find minimum latency configuration\n",
    "    for j in range(1, num_devices + 1):  # Device count\n",
    "        for i in range(1, number_of_nodes + 1):  # End layer for this device\n",
    "            for k in range(i):  # Split point\n",
    "                # Resource constraints check\n",
    "                print(\"\\ndevices[j-1][\\\"maxLUT\\\"]\\t\" + str(devices[j-1][\"maxLUT\"]))\n",
    "                print(\"lut_usage[k][i - 1]\\t\" + str(lut_usage[k][i - 1]))\n",
    "                print(\"devices[j-1][\\\"maxBRAM\\\"]\\t\" + str(devices[j-1][\"maxBRAM\"]))\n",
    "                print(\"bram_usage[k][i - 1]\\t\" + str(bram_usage[k][i - 1]))\n",
    "                \n",
    "                if lut_usage[k][i - 1] <= devices[j-1][\"maxLUT\"] and bram_usage[k][i - 1] <= devices[j-1][\"maxBRAM\"]:\n",
    "                    # Calculate latency for the current split configuration\n",
    "                    comm_latency = output_sizes[k - 1] * 0.01 if k > 0 else 0\n",
    "                    current_latency = dp[k][j - 1] + execution_latency[k][i - 1] + comm_latency\n",
    "                    print(\"comm_latency:\\t\" + str(comm_latency))\n",
    "                    # Update dp table if current latency is lower\n",
    "                    if current_latency < dp[i][j]:\n",
    "                        dp[i][j] = current_latency\n",
    "                        split_point[i][j] = k\n",
    "\n",
    "\n",
    "    # Find the minimum latency for the full model on the available devices\n",
    "    min_latency = min(dp[number_of_nodes][j] for j in range(1, num_devices + 1))\n",
    "    optimal_devices = min(range(0, num_devices + 1), key=lambda j: dp[number_of_nodes][j])\n",
    "\n",
    "    # Reconstruct the optimal device assignment from split_point table\n",
    "    def reconstruct_layers():\n",
    "        assignments = []\n",
    "        i, j = number_of_nodes, optimal_devices\n",
    "        while j > 1:\n",
    "            start_layer = split_point[i][j] #+ 1\n",
    "            assignments.append((start_layer, i - 1))\n",
    "            i, j = start_layer, j - 1\n",
    "        return assignments[::-1]\n",
    "\n",
    "    # Output results\n",
    "    optimal_assignment = reconstruct_layers()\n",
    "    optimal_devices -= 1\n",
    "    return {\n",
    "        \"min_latency\": min_latency,\n",
    "        \"optimal_devices\": optimal_devices,\n",
    "        \"assignments\": optimal_assignment\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e499b1-8958-4821-a719-bfa2135d8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    layer_latency = [30720, 8196.0, 324000, 142920, 282240, 9800, 26760, 207360, 37440, 288000, 1250, 3840, 207360, 1440,184320 ,327680, 327680, 5120, 20]  # Latency for each layer\n",
    "    layer_resources = [16.0, 396.0, 2746.0, 428.0, 7410.0, 0, 428.0, 3855.0, 428.0, 3872.0, 0, 428.0, 1193.0, 428.0, 524.0,  336.0,363.0, 335.0, 0 ]  # Resource usage for each layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3db982-c6fd-4171-b9af-b735625435d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_partition_dp(model_folded_path, maxNumberOfDevices, devices, number_of_nodes):\n",
    "    dp = [[float('inf')] * (maxNumberOfDevices + 1) for _ in range(number_of_nodes + 1)]\n",
    "    dp[0][0] = 0  # Base case: zero layers has zero latency\n",
    "    # To store the path to backtrack the optimal configuration\n",
    "    prev = [[-1] * (maxNumberOfDevices + 1) for _ in range(number_of_nodes + 1)]\n",
    "    \n",
    "    # Step 2: Fill DP Table\n",
    "    for j in range(1, maxNumberOfDevices + 1):  # Device count\n",
    "        for i in range(1, number_of_nodes + 1):  # Layer count\n",
    "            \n",
    "            current_resource_usage = 0\n",
    "            current_latency = 0\n",
    "            \n",
    "            for k in range(i):  # Starting layer of the current block\n",
    "                # Step 3: Quantize and estimate latency for block from k to i\n",
    "\n",
    "                start_node = k\n",
    "                end_node = i\n",
    "                block_path, last_output_shape, last_output_dtype = get_one_layer(model_folded_path, start_node, end_node)\n",
    "                block = ModelWrapper(block_path)\n",
    "                estimate_layer_resources, estimate_network_performance = generateReport(block, 10)\n",
    "                \n",
    "                # Resource constraints\n",
    "                if (float(estimate_layer_resources[\"total\"][\"LUT\"]) <= float(devices[j-1][\"maxLUT\"]) and\n",
    "                    float(estimate_layer_resources[\"total\"][\"BRAM_18K\"]) <= float(devices[j-1][\"maxBRAM\"])):\n",
    "\n",
    "                    # Communication cost\n",
    "                    communication_cost = estimate_communication_cost(last_output_shape, last_output_dtype, 100, communication_protocol)\n",
    "                    \n",
    "                    # Total latency\n",
    "                    print(str(dp[k][j-1]) + \"\\t\" + str(float(estimate_network_performance[\"estimated_latency_ns\"])) + \"\\t\" + str(communication_cost))\n",
    "                    total_latency = dp[k][j-1] + float(estimate_network_performance[\"estimated_latency_ns\"]) + communication_cost\n",
    "                    \n",
    "                    # Update DP table if this configuration is better\n",
    "                    print(total_latency)\n",
    "                    if total_latency < dp[i][j]:\n",
    "                        dp[i][j] = total_latency\n",
    "                        prev[i][j] = (k, estimate_layer_resources, estimate_network_performance, communication_cost)\n",
    "                        #prev[i][j] = (k, communication_cost)\n",
    "    \n",
    "    # Step 4: Backtrack to find optimal configuration\n",
    "    optimal_configuration = []\n",
    "    i, j = number_of_nodes, maxNumberOfDevices\n",
    "    while i > 0 and j > 0:\n",
    "        if prev[i][j] is not None:\n",
    "            k, estimate_layer_resources, estimate_network_performance, communication_cost = prev[i][j]\n",
    "            #k, communication_cost = prev[i][j]\n",
    "            optimal_configuration.append({\n",
    "                \"start_layer\": k,\n",
    "                \"end_layer\": i,\n",
    "                \"estimate_layer_resources\": str(estimate_layer_resources),\n",
    "                \"estimate_network_performance\": str(estimate_network_performance),\n",
    "                \"communication_cost\": communication_cost\n",
    "            })\n",
    "        i, j = k, j - 1\n",
    "\n",
    "    optimal_configuration.reverse()  # Order the blocks from first to last\n",
    "    min_latency = dp[number_of_nodes][maxNumberOfDevices]\n",
    "    print(min_latency)\n",
    "    print(optimal_configuration)\n",
    "    \n",
    "    return (min_latency, optimal_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588f187-2978-4c62-b7ec-4139c31de3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_partition_dp(model_folded_path, maxNumberOfDevices, devices, number_of_nodes):\n",
    "    \n",
    "    dp = [[float('inf')] * (number_of_nodes + 1) for _ in range(maxNumberOfDevices + 1)]\n",
    "    dp[0][0] = 0  # Base case: zero layers has zero latency\n",
    "    # To store the path to backtrack the optimal configuration\n",
    "    prev = [[-1] * (number_of_nodes + 1) for _ in range(maxNumberOfDevices + 1)]\n",
    "    #print(dp)\n",
    "\n",
    "    layer_latency = [30720, 8196.0, 324000, 142920, 282240, 9800, 26760, 207360, 37440, 288000, 1250, 3840, 207360, 1440,184320 ,327680, 327680, 5120, 20]  # Latency for each layer\n",
    "    layer_resources = [16.0, 396.0, 2746.0, 428.0, 7410.0, 0, 428.0, 3855.0, 428.0, 3872.0, 0, 428.0, 1193.0, 428.0, 524.0,  336.0,363.0, 335.0, 0 ]  # Resource usage for each layer\n",
    "    \n",
    "    # Step 2: Fill DP Table\n",
    "    for i in range(1, maxNumberOfDevices + 1):  # Device count\n",
    "        \n",
    "        LUT_LIMIT = 240000#float(estimate_layer_resources[\"total\"][\"LUT\"])\n",
    "                          \n",
    "        for j in range(1, number_of_nodes + 1):  # Layer count\n",
    "            \n",
    "            current_resource_usage = 0\n",
    "            current_latency = 0\n",
    "\n",
    "            for k in range(j, 0, -1):  # k is the start layer of the block\n",
    "                current_resource_usage += layer_resources[k-1]\n",
    "                current_latency += layer_latency[k-1]\n",
    "    \n",
    "                # Ensure resource constraints are met\n",
    "                if current_resource_usage > LUT_LIMIT:\n",
    "                    break  # Stop if current block exceeds resource limits\n",
    "    \n",
    "                # Update dp[i][j] if it reduces the minimum latency\n",
    "                #print(\"dp[1][3]:\" + str(dp[1][3]))\n",
    "                #print(\"i:\" + str(i)+ \"\\tj:\"  + str(j) + \"\\tk:\"  + str(k))\n",
    "                if dp[i][j] > dp[i-1][k-1] + current_latency:\n",
    "                    dp[i][j] = dp[i-1][k-1] + current_latency\n",
    "                    prev[i][j] = k  # Track where the current block starts\n",
    "\n",
    "    if dp[maxNumberOfDevices][number_of_nodes] == float('inf'):\n",
    "        print(\"No feasible solution found.\")\n",
    "    else:\n",
    "        print(\"Minimum latency:\", dp[maxNumberOfDevices][number_of_nodes])\n",
    "    \n",
    "        # Backtrack to find optimal partitioning\n",
    "        partitions = []\n",
    "        remaining_layers = number_of_nodes\n",
    "        fpgas_used = maxNumberOfDevices\n",
    "        while remaining_layers > 0 and fpgas_used > 0:\n",
    "            start_layer = prev[fpgas_used][remaining_layers]\n",
    "            partitions.append((start_layer, remaining_layers))\n",
    "            remaining_layers = start_layer - 1\n",
    "            fpgas_used -= 1\n",
    "    \n",
    "        # Reverse to print in order\n",
    "        partitions.reverse()\n",
    "        print(\"Optimal partitions (start_layer, end_layer):\", partitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232113c-f396-4f9a-998f-c6825084652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_latency = dp[i-1][k-1] + current_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0fef4-c829-4fe1-b300-83fca3e8d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "INT8 = 8\n",
    "BINARY = 1\n",
    "UINT32 = 32\n",
    "def find_optimal_partition_dp(model_folded_path, maxNumberOfDevices, devices, number_of_nodes, com_frequency):\n",
    "\n",
    "    protocol = 1\n",
    "    \n",
    "    dp = [[float('inf')] * (number_of_nodes + 1) for _ in range(maxNumberOfDevices + 1)]\n",
    "    dp[0][0] = 0  # Base case: zero layers has zero latency\n",
    "    \n",
    "    # To store the path to backtrack the optimal configuration\n",
    "    prev = [[-1] * (number_of_nodes + 1) for _ in range(maxNumberOfDevices + 1)]\n",
    "\n",
    "    node_latency = [30720, 8196.0, 324000, 142920, 282240, 9800, 26760, 207360, 37440, 288000, 1250, 3840, 207360, 1440,184320 ,327680, 327680, 5120, 20]  \n",
    "    node_lut = [16.0, 396.0, 2746.0, 428.0, 7410.0, 0, 428.0, 3855.0, 428.0, 3872.0, 0, 428.0, 1193.0, 428.0, 524.0,  336.0,363.0, 335.0, 0 ]  \n",
    "    last_output_shape = [[1, 32, 32, 3],[1, 30, 30, 27],[1, 30, 30, 64],[1, 28, 28, 576],[1, 28, 28, 64],[1, 14, 14, 64],[1, 12, 12, 576],[1, 12, 12, 128],[1, 10, 10, 1152],[1, 10, 10, 128],[1, 5, 5, 128],[1, 3, 3, 1152],[1, 3, 3, 256],[1, 1, 1, 2304],[1, 1, 1, 256],[1, 512],[1, 512],[1, 2],[1, 1]]\n",
    "    last_output_dtype = [INT8,INT8,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,UINT32,BINARY]\n",
    "\n",
    "    \n",
    "    # Fill DP Table\n",
    "    for i in range(1, maxNumberOfDevices + 1):  # Device count\n",
    "        \n",
    "        LUT_MAX = 22000 \n",
    "        BRAM_MAX = 0\n",
    "                          \n",
    "        for j in range(1, number_of_nodes + 1):  # Layer count\n",
    "            current_lut_usage = 0\n",
    "            current_latency = 0\n",
    "\n",
    "            \n",
    "            COMM_LATENCY = estimate_communication_cost(last_output_shape[j-1], last_output_dtype[j-1], com_frequency, protocol)\n",
    "            \n",
    "            for k in range(j, 0, -1):  # k is the start layer of the block\n",
    "                current_lut_usage += node_lut[k-1]\n",
    "                current_latency += node_latency[k-1]\n",
    "    \n",
    "                # Ensure resource constraints are met\n",
    "                # Stop if current block exceeds resource limits\n",
    "                if current_lut_usage > LUT_MAX:\n",
    "                    break  \n",
    "    \n",
    "                # Calculate the cost of using this configuration\n",
    "                added_latency = dp[i-1][k-1] + current_latency\n",
    "\n",
    "                # Add communication latency if moving to a new FPGA\n",
    "                # TODO: make the communication latency as variable\n",
    "                if i > 1:  \n",
    "                    added_latency += COMM_LATENCY\n",
    "                    #print(COMM_LATENCY)\n",
    "                    \n",
    "                # Update dp[i][j] if it reduces the minimum latency\n",
    "                if dp[i][j] > added_latency:\n",
    "                    dp[i][j] = added_latency\n",
    "                    prev[i][j] = k  # Track where the current block starts\n",
    "\n",
    "\n",
    "    # Find the minimum latency across all configurations using up to maxNumberOfDevices Devices\n",
    "    min_latency = float('inf')\n",
    "    optimal_device_count = 0\n",
    "    for i in range(1, maxNumberOfDevices + 1):\n",
    "        if dp[i][number_of_nodes] < min_latency:\n",
    "            min_latency = dp[i][number_of_nodes]\n",
    "            optimal_device_count = i\n",
    "    \n",
    "    # Output the result\n",
    "    if min_latency == float('inf'):\n",
    "        print(\"No feasible solution found.\")\n",
    "    else:\n",
    "        print(f\"Minimum latency: {min_latency} using {optimal_device_count} FPGA(s)\")\n",
    "    \n",
    "        # Backtrack to find the optimal partitioning for the minimum FPGA count\n",
    "        partitions = []\n",
    "        remaining_nodes = number_of_nodes\n",
    "        device_used = optimal_device_count\n",
    "        while remaining_nodes > 0 and device_used > 0:\n",
    "            start_node = prev[device_used][remaining_nodes]\n",
    "            partitions.append((start_node, remaining_nodes))\n",
    "            remaining_nodes = start_node - 1\n",
    "            device_used -= 1\n",
    "    \n",
    "        # Reverse to print in order\n",
    "        partitions.reverse()\n",
    "        print(\"Optimal partitions (start_layer, end_layer):\", partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd9125-de68-4b76-b12a-7ed41c676208",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    for i in range(1, maxNumberOfDevices + 1):  # Device count\n",
    "        \n",
    "        LUT_LIMIT = 240000#float(estimate_layer_resources[\"total\"][\"LUT\"])\n",
    "                          \n",
    "        for j in range(1, number_of_nodes + 1):  # Layer count\n",
    "            \n",
    "            current_resource_usage = 0\n",
    "            current_latency = 0\n",
    "\n",
    "            for k in range(j, 0, -1):  # k is the start layer of the block\n",
    "                current_resource_usage += layer_resources[k-1]\n",
    "                current_latency += layer_latency[k-1]\n",
    "    \n",
    "                # Ensure resource constraints are met\n",
    "                if current_resource_usage > LUT_LIMIT:\n",
    "                    break  # Stop if current block exceeds resource limits\n",
    "    \n",
    "                # Update dp[i][j] if it reduces the minimum latency\n",
    "                #print(\"dp[1][3]:\" + str(dp[1][3]))\n",
    "                #print(\"i:\" + str(i)+ \"\\tj:\"  + str(j) + \"\\tk:\"  + str(k))\n",
    "                if dp[i][j] > dp[i-1][k-1] + current_latency:\n",
    "                    dp[i][j] = dp[i-1][k-1] + current_latency\n",
    "                    prev[i][j] = k  # Track where the current block starts\n",
    "\n",
    "    if dp[maxNumberOfDevices][number_of_nodes] == float('inf'):\n",
    "        print(\"No feasible solution found.\")\n",
    "    else:\n",
    "        print(\"Minimum latency:\", dp[maxNumberOfDevices][number_of_nodes])\n",
    "    \n",
    "        # Backtrack to find optimal partitioning\n",
    "        partitions = []\n",
    "        remaining_layers = number_of_nodes\n",
    "        fpgas_used = maxNumberOfDevices\n",
    "        while remaining_layers > 0 and fpgas_used > 0:\n",
    "            start_layer = prev[fpgas_used][remaining_layers]\n",
    "            partitions.append((start_layer, remaining_layers))\n",
    "            remaining_layers = start_layer - 1\n",
    "            fpgas_used -= 1\n",
    "    \n",
    "        # Reverse to print in order\n",
    "        partitions.reverse()\n",
    "        print(\"Optimal partitions (start_layer, end_layer):\", partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ee5b7-f266-4782-bdb1-37964018ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INT8 = 8\n",
    "BINARY = 1\n",
    "UINT32 = 32\n",
    "def find_optimal_partition_dp(model_folded_path, maxNumberOfDevices, devices, number_of_nodes, com_frequency):\n",
    "\n",
    "    protocol = 1\n",
    "    \n",
    "    dp = [[float('inf')] * (number_of_nodes + 1) for _ in range(maxNumberOfDevices + 1)]\n",
    "    dp[0][0] = 0  # Base case: zero layers has zero latency\n",
    "    \n",
    "    # To store the path to backtrack the optimal configuration\n",
    "    prev = [[-1] * (number_of_nodes + 1) for _ in range(maxNumberOfDevices + 1)]\n",
    "\n",
    "    node_latency = [30720, 8196.0, 324000, 142920, 282240, 9800, 26760, 207360, 37440, 288000, 1250, 3840, 207360, 1440,184320 ,327680, 327680, 5120, 20]  \n",
    "    node_lut = [16.0, 396.0, 2746.0, 428.0, 7410.0, 0, 428.0, 3855.0, 428.0, 3872.0, 0, 428.0, 1193.0, 428.0, 524.0,  336.0,363.0, 335.0, 0 ]  \n",
    "    last_output_shape = [[1, 32, 32, 3],[1, 30, 30, 27],[1, 30, 30, 64],[1, 28, 28, 576],[1, 28, 28, 64],[1, 14, 14, 64],[1, 12, 12, 576],[1, 12, 12, 128],[1, 10, 10, 1152],[1, 10, 10, 128],[1, 5, 5, 128],[1, 3, 3, 1152],[1, 3, 3, 256],[1, 1, 1, 2304],[1, 1, 1, 256],[1, 512],[1, 512],[1, 2],[1, 1]]\n",
    "    last_output_dtype = [INT8,INT8,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,BINARY,UINT32,BINARY]\n",
    "\n",
    "    node_output_size = []\n",
    "    for n in last_output_shape:\n",
    "        elements = 0\n",
    "        for i in n:\n",
    "            elements *=elements \n",
    "        node_output_size.append(elements)\n",
    "    \n",
    "    # Fill DP Table\n",
    "    for i in range(1, maxNumberOfDevices + 1):  # Device count\n",
    "        \n",
    "        LUT_MAX = 23000 \n",
    "        BRAM_MAX = 0\n",
    "                          \n",
    "        for j in range(1, number_of_nodes + 1):  # Layer count\n",
    "            current_lut_usage = 0\n",
    "            current_latency = 0\n",
    "\n",
    "            \n",
    "            COMM_LATENCY = estimate_communication_cost(last_output_shape[j-1], last_output_dtype[j-1], com_frequency, protocol)\n",
    "            \n",
    "            for k in range(j, 0, -1):  # k is the start layer of the block\n",
    "                current_lut_usage += node_lut[k-1]\n",
    "                current_latency += node_latency[k-1]\n",
    "    \n",
    "                # Ensure resource constraints are met\n",
    "                # Stop if current block exceeds resource limits\n",
    "                if current_lut_usage > LUT_MAX:\n",
    "                    break  \n",
    "    \n",
    "                # Calculate the cost of using this configuration\n",
    "                added_latency = dp[i-1][k-1] + current_latency\n",
    "\n",
    "                # Add communication latency if moving to a new FPGA\n",
    "                # TODO: make the communication latency as variable\n",
    "                if i > 1:  \n",
    "                    added_latency += COMM_LATENCY\n",
    "                    #print(COMM_LATENCY)\n",
    "                    \n",
    "                # Update dp[i][j] if it reduces the minimum latency\n",
    "                if dp[i][j] > added_latency:\n",
    "                    dp[i][j] = added_latency\n",
    "                    prev[i][j] = k  # Track where the current block starts\n",
    "\n",
    "\n",
    "    # Find the minimum latency across all configurations using up to maxNumberOfDevices Devices\n",
    "    min_latency = float('inf')\n",
    "    optimal_device_count = 0\n",
    "    for i in range(1, maxNumberOfDevices + 1):\n",
    "        if dp[i][number_of_nodes] < min_latency:\n",
    "            min_latency = dp[i][number_of_nodes]\n",
    "            optimal_device_count = i\n",
    "    \n",
    "    # Output the result\n",
    "    if min_latency == float('inf'):\n",
    "        print(\"No feasible solution found.\")\n",
    "    else:\n",
    "        print(f\"Minimum latency: {min_latency} using {optimal_device_count} FPGA(s)\")\n",
    "    \n",
    "        # Backtrack to find the optimal partitioning for the minimum FPGA count\n",
    "        partitions = []\n",
    "        remaining_nodes = number_of_nodes\n",
    "        device_used = optimal_device_count\n",
    "        while remaining_nodes > 0 and device_used > 0:\n",
    "            start_node = prev[device_used][remaining_nodes]\n",
    "            partitions.append((start_node, remaining_nodes))\n",
    "            remaining_nodes = start_node - 1\n",
    "            device_used -= 1\n",
    "    \n",
    "        # Reverse to print in order\n",
    "        partitions.reverse()\n",
    "        print(\"Optimal partitions (start_layer, end_layer):\", partitions)\n",
    "\n",
    "    initial_partitions = partitions\n",
    "    # Phase 2: Communication cost optimization\n",
    "\n",
    "    optimized_partitions = []\n",
    "    for i, (start, end) in enumerate(initial_partitions):\n",
    "        min_block_latency = float('inf')\n",
    "        best_split = start\n",
    "    \n",
    "        # Explore alternative split points within each partition to minimize communication cost\n",
    "        for split_point in range(start, end):\n",
    "            block_latency = 0\n",
    "            for node in range(start, split_point + 1):\n",
    "                block_latency += node_latency[node - 1]\n",
    "    \n",
    "            # Compute communication cost for this partition point\n",
    "            comm_latency = 0#estimate_communication_cost(last_output_shape[split_point-1], last_output_dtype[split_point-1], com_frequency, protocol) #node_output_size[split_point - 1] * COMM_COST_MULTIPLIER if i > 0 else 0\n",
    "            total_latency = block_latency + comm_latency\n",
    "    \n",
    "            # Find the split point with the minimum latency for this partition\n",
    "            if total_latency < min_block_latency:\n",
    "                min_block_latency = total_latency\n",
    "                best_split = split_point\n",
    "    \n",
    "        # Append optimized split point for this FPGA\n",
    "        optimized_partitions.append((best_split, end))\n",
    "    \n",
    "    print(\"Optimized partitions (start_layer, end_layer):\", optimized_partitions)\n",
    "    \n",
    "    # Output the final results\n",
    "    final_latency = sum(dp[optimal_device_count][partition[1]] for partition in optimized_partitions)\n",
    "    print(f\"Final minimum latency after optimization: {final_latency}\")\n",
    "    print(\"Optimized partitions:\", optimized_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ceda50-b201-48c4-af93-e50771993b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_optimal_partition_dp(model_folded_path, maxNumberOfDevices, devices, number_of_nodes, com_frequency):\n",
    "\n",
    "    \n",
    "    dp = [[float('inf')] * (number_of_nodes + 1) for _ in range(maxNumberOfDevices + 1)]\n",
    "    dp[0][0] = 0  # Base case: zero layers has zero latency\n",
    "    \n",
    "    # To store the path to backtrack the optimal configuration\n",
    "    prev = [[-1] * (number_of_nodes + 1) for _ in range(maxNumberOfDevices + 1)]\n",
    "\n",
    "    \n",
    "\n",
    "    node_output_size = []\n",
    "    for n in last_output_shape:\n",
    "        elements = 0\n",
    "        for i in n:\n",
    "            elements *=elements \n",
    "        node_output_size.append(elements)\n",
    "    \n",
    "    # Fill DP Table\n",
    "    for i in range(1, maxNumberOfDevices + 1):  # Device count\n",
    "        \n",
    "        LUT_MAX = 23000 \n",
    "        BRAM_MAX = 0\n",
    "                          \n",
    "        for j in range(1, number_of_nodes + 1):  # Layer count\n",
    "            current_lut_usage = 0\n",
    "            current_latency = 0\n",
    "\n",
    "            \n",
    "            COMM_LATENCY = estimate_communication_cost(last_output_shape[j-1], last_output_dtype[j-1], com_frequency, protocol)\n",
    "            \n",
    "            for k in range(j, 0, -1):  # k is the start layer of the block\n",
    "                current_lut_usage += node_lut[k-1]\n",
    "                current_latency += node_latency[k-1]\n",
    "    \n",
    "                # Ensure resource constraints are met\n",
    "                # Stop if current block exceeds resource limits\n",
    "                if current_lut_usage > LUT_MAX:\n",
    "                    break  \n",
    "    \n",
    "                # Calculate the cost of using this configuration\n",
    "                added_latency = dp[i-1][k-1] + current_latency\n",
    "\n",
    "                # Add communication latency if moving to a new FPGA\n",
    "                # TODO: make the communication latency as variable\n",
    "                if i > 1:  \n",
    "                    added_latency += COMM_LATENCY\n",
    "                    #print(COMM_LATENCY)\n",
    "                    \n",
    "                # Update dp[i][j] if it reduces the minimum latency\n",
    "                if dp[i][j] > added_latency:\n",
    "                    dp[i][j] = added_latency\n",
    "                    prev[i][j] = k  # Track where the current block starts\n",
    "\n",
    "\n",
    "    # Find the minimum latency across all configurations using up to maxNumberOfDevices Devices\n",
    "    min_latency = float('inf')\n",
    "    optimal_device_count = 0\n",
    "    for i in range(1, maxNumberOfDevices + 1):\n",
    "        if dp[i][number_of_nodes] < min_latency:\n",
    "            min_latency = dp[i][number_of_nodes]\n",
    "            optimal_device_count = i\n",
    "    \n",
    "    # Output the result\n",
    "    if min_latency == float('inf'):\n",
    "        print(\"No feasible solution found.\")\n",
    "    else:\n",
    "        print(f\"Minimum latency: {min_latency} using {optimal_device_count} FPGA(s)\")\n",
    "    \n",
    "        # Backtrack to find the optimal partitioning for the minimum FPGA count\n",
    "        partitions = []\n",
    "        remaining_nodes = number_of_nodes\n",
    "        device_used = optimal_device_count\n",
    "        while remaining_nodes > 0 and device_used > 0:\n",
    "            start_node = prev[device_used][remaining_nodes]\n",
    "            partitions.append((start_node, remaining_nodes))\n",
    "            remaining_nodes = start_node - 1\n",
    "            device_used -= 1\n",
    "    \n",
    "        # Reverse to print in order\n",
    "        partitions.reverse()\n",
    "        print(\"Optimal partitions (start_layer, end_layer):\", partitions)\n",
    "\n",
    "    initial_partitions = partitions\n",
    "    # Phase 2: Communication cost optimization\n",
    "\n",
    "    optimized_partitions = []\n",
    "    for i, (start, end) in enumerate(initial_partitions):\n",
    "        min_block_latency = float('inf')\n",
    "        best_split = start\n",
    "    \n",
    "        # Explore alternative split points within each partition to minimize communication cost\n",
    "        for split_point in range(start, end):\n",
    "            block_latency = 0\n",
    "            for node in range(start, split_point + 1):\n",
    "                block_latency += node_latency[node - 1]\n",
    "    \n",
    "            # Compute communication cost for this partition point\n",
    "            comm_latency = 0#estimate_communication_cost(last_output_shape[split_point-1], last_output_dtype[split_point-1], com_frequency, protocol) #node_output_size[split_point - 1] * COMM_COST_MULTIPLIER if i > 0 else 0\n",
    "            total_latency = block_latency + comm_latency\n",
    "    \n",
    "            # Find the split point with the minimum latency for this partition\n",
    "            if total_latency < min_block_latency:\n",
    "                min_block_latency = total_latency\n",
    "                best_split = split_point\n",
    "    \n",
    "        # Append optimized split point for this FPGA\n",
    "        optimized_partitions.append((best_split, end))\n",
    "    \n",
    "    print(\"Optimized partitions (start_layer, end_layer):\", optimized_partitions)\n",
    "    \n",
    "    # Output the final results\n",
    "    final_latency = sum(dp[optimal_device_count][partition[1]] for partition in optimized_partitions)\n",
    "    print(f\"Final minimum latency after optimization: {final_latency}\")\n",
    "    print(\"Optimized partitions:\", optimized_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70759131-2a2b-4a0b-bef0-2f4c63b691e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(19):\n",
    "    print(estimate_communication_cost(last_output_shape[i], last_output_dtype[i],100000000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb6ae5-fad0-4948-bb7c-b197b6f665b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def optimal_partitioning(model_folded_path, maxNumberOfDevices, devices, number_of_nodes, com_frequency, com_protocol):\n",
    "    # Initialize DP table: dp[i][j] where i is layer index, j is device index\n",
    "    dp = np.full((number_of_nodes + 1, maxNumberOfDevices + 1), float('inf'))\n",
    "    path = [[[] for _ in range(maxNumberOfDevices + 1)] for _ in range(number_of_nodes + 1)]\n",
    "    dp[0][0] = 0  # Base case: no layers and no devices has zero latency\n",
    "    \n",
    "    # Fill the DP table\n",
    "    for i in range(1, number_of_nodes + 1):           # {1,...,18} end block\n",
    "        for j in range(1, maxNumberOfDevices + 1):    # {1,...,3}\n",
    "            for k in range(i):                        # satrt block\n",
    "                \n",
    "                # Calculate the latency and resource usage of block from layer k to i\n",
    "                block_latency, block_LUT, block_BRAM, comm_cost = 0, 0, 0, 0\n",
    "                \n",
    "                for node in range(k,i):               # block report\n",
    "                    block_latency += node_latency[k]\n",
    "                    block_LUT += node_lut[k]\n",
    "                    block_BRAM += 1\n",
    "                    if k > 0:\n",
    "                        comm_cost = estimate_communication_cost(last_output_shape[i-1], last_output_dtype[i-1], com_frequency, com_protocol)  #layers[k-1].output_size  # Communication cost at split point\n",
    " \n",
    "                # Check constraints\n",
    "                if block_LUT <= max_LUT and block_BRAM <= max_BRAM:\n",
    "                    total_latency = dp[k][j-1] + block_latency + comm_cost\n",
    "                    # Update DP if this split gives a lower latency\n",
    "                    \n",
    "                    if total_latency < dp[i][j]:\n",
    "                        dp[i][j] = total_latency\n",
    "                        path[i][j] = path[k][j-1] + [(k, i)]  # Record split point\n",
    "    \n",
    "    # Find the minimum latency configuration\n",
    "    min_latency, optimal_devices = float('inf'), 0\n",
    "    optimal_modules = []\n",
    "    for j in range(1, maxNumberOfDevices + 1):\n",
    "        if dp[number_of_nodes][j] < min_latency:\n",
    "            min_latency = dp[number_of_nodes][j]\n",
    "            optimal_devices = j\n",
    "            optimal_modules = path[number_of_nodes][j]\n",
    "    \n",
    "    return optimal_devices, optimal_modules, min_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ace42-6612-4d14-a218-f825b84c08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_optimal_partition_dp(model_folded_path, maxNumberOfDevices, devices, number_of_nodes, 10000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
